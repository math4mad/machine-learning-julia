---
title: "ensemblemodel-with-bostonhouse"
---

:::{.callout-note title="info"}
 `Random Forest` :ref  [What is random forest?](https://www.ibm.com/topics/random-forest#)
:::

## 1. loading package
```{julia}
using MLJ
import DataFrames: DataFrame
using PrettyPrinting
using StableRNGs
using CairoMakie,AlgebraOfGraphics,MakieThemes
rng = StableRNG(512)
```

## 2. load data
```{julia}
X, y = @load_boston
```

## 3. single model 
### 3.1 load  model
```{julia}
DecisionTreeRegressor = @load DecisionTreeRegressor pkg=DecisionTree
``` 
### 3.2 instantiate and evaulate model
```{julia}
tree = machine(DecisionTreeRegressor(), X, y)
e = evaluate!(tree, resampling=Holdout(fraction_train=0.8),
              measure=[rms, rmslp1])
```

## 4. Ensemble mode : Random Forest
### 4.1 instantiate  random forest
```{julia}
forest = EnsembleModel(model=DecisionTreeRegressor())
forest.model.n_subfeatures = 3
```

### 4.2  by learning curve to get best trees 

```{julia}
rng = StableRNG(5123) # for reproducibility
m = machine(forest, X, y)
r = range(forest, :n, lower=10, upper=1000)
curves = MLJ.learning_curve(m, resampling=Holdout(fraction_train=0.8, rng=rng),
                         range=r, measure=rms);
```

```{julia}
let
  ax=(width = 400, height = 400,xlabel="rmsr",ylabel="numbers of trees")
  datalayer=data((parameter_values=curves.parameter_values,measurements=curves.measurements))
  mappinglayer=mapping(:parameter_values,:measurements)
  vislayer=visual(Lines,color=:blue)
  plt=datalayer*mappinglayer*vislayer
  draw(plt, axis=ax)
end
```

### 4.3 setting  `150` trees
```{julia}
forest.n = 150;
```

### 4.4 setting tunning parameters  range
```{julia}
r_sf = range(forest, :(model.n_subfeatures), lower=1, upper=12)
r_bf = range(forest, :bagging_fraction, lower=0.4, upper=1.0);
```

### 4.4 tuning random forest 
```{julia}
tuned_forest = TunedModel(model=forest,
                          tuning=Grid(resolution=3),
                          resampling=CV(nfolds=6, rng=StableRNG(32)),
                          ranges=[r_sf, r_bf],
                          measure=rms)
m = machine(tuned_forest, X, y)
e = evaluate!(m, resampling=Holdout(fraction_train=0.8),
              measure=[rms, rmslp1])
e
```


```{julia}
r = report(m)
```

### 4.5 plot tunning results 

```{julia}
#| label: fig-ensemble-params-tunning
#| fig-cap: "fig-ensemble-params-tunning"
#| fig-cap-location : margin
#| fig-align: "center"
#| warning: false
res = r.plotting
table=(vals_b = res.parameter_values[:, 1],
            vals_k = res.parameter_values[:, 2],
            measurement=res.measurements
)

datalayer=data(table)
mappinglayer=mapping(:vals_b,:vals_k,:measurement,color=:measurement)
vislayler=visual(Tricontourf,colormap = :batlow)
ax=(width = 400, height = 400)
plt=datalayer*mappinglayer*vislayler
draw(plt,axis=ax)
```


### 4.6 predict with ensemble model 
```{julia}
ŷ = predict(m,X)
@show rms(ŷ, y)

```